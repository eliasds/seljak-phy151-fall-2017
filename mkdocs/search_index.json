{
    "docs": [
        {
            "location": "/",
            "text": "Welcome to MkDocs\n\n\nFor full documentation visit \nmkdocs.org\n.\n\n\nCommands\n\n\n\n\nmkdocs new [dir-name]\n - Create a new project.\n\n\nmkdocs serve\n - Start the live-reloading docs server.\n\n\nmkdocs build\n - Build the documentation site.\n\n\nmkdocs help\n - Print this help message.\n\n\n\n\nProject layout\n\n\nmkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.",
            "title": "Home"
        },
        {
            "location": "/#welcome-to-mkdocs",
            "text": "For full documentation visit  mkdocs.org .",
            "title": "Welcome to MkDocs"
        },
        {
            "location": "/#commands",
            "text": "mkdocs new [dir-name]  - Create a new project.  mkdocs serve  - Start the live-reloading docs server.  mkdocs build  - Build the documentation site.  mkdocs help  - Print this help message.",
            "title": "Commands"
        },
        {
            "location": "/#project-layout",
            "text": "mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.",
            "title": "Project layout"
        },
        {
            "location": "/README/",
            "text": "Computational Physics: numerical methods, data science and statistics\n\n\nThe purpose of the course is to get aquainted with modern computational methods \nused in physics, including numerical analysis methods, data science and statistics. \nWe will also explore numerical and statistical methods that have been inspired by physics \nand/or created by physicists. Historically many of the methods have been developed for physics \napplications, a trend that continues today with more modern examples like Metropolis \nalgorithm, simulated annealing and Hamiltonian Monte Carlo.  \n\n\nEach week there will be a set of lectures discussing theoretical and practical underpinnings of the specific topic, \ntogether with its most common applications in physics and astronomy, followed by a homework assignment applying the \nmethods to physics and astronomy based applications. \n\n\nSyllabus\n\n\n\n\n\n\nFunction Integration: trapezoidal, Simpson, Romberg, gaussian quadratures\n\n\n\n\n\n\nSpecial functions and function evaluation: Gamma, Bessel, spherical harmonics, function derivatives\n\n\n\n\n\n\nSolving Linear Algebra: Gauss elimination, LU and Cholesky decomposition, singular value decomposition, sparse algebra\n\n\n\n\n\n\nEigensystems and matrix diagonalization, principal component analysis\n\n\n\n\n\n\nNonlinear sets of equations: relaxation, bisection, Newton's method\n\n\n\n\n\n\nOptimization (minimization/maximization): steepest gradient descent, stochastic gradient descent, conjugate gradient, Newton and quasi-Newton (BFGS)\n\n\n\n\n\n\nInterpolation and extrapolation of data. Polynomial, rational and spline interpolation, gaussian process\n\n\n\n\n\n\nFourier transforms: FFT, convolutions, power spectrum and correlation function, optimal (Wiener) filtering, wavelets\n\n\n\n\n\n\nOrdinary differential equations: Euler, Runge Kutta, Bulirsch-Stoer, stiff equation solvers, leap-frog, boundary value problems\n\n\n\n\n\n\nPartial differential equations: boundary value and initial value problems\n\n\n\n\n\n\nStatistics: Bayes theorem, priors and posteriors, maximum likelihood and maximum a posterior, linear and \nnonlinear model fitting of data. Error estimation: covariance and Fisher information matrix, jackknife, bootstrap\n\n\n\n\n\n\nRandom processes and statistics: random number generators, Monte Carlo integration, \nMetropolois algorithm, Markov Chain Monte Carlo, Gibbs sampling, importance sampling, Hamiltonian Monte \nCarlo, simulated annealing\n\n\n\n\n\n\nClassification and Inference with Machine Learning and Bayesian Statistics: Gaussian mixtures with expectation \nmaximization algorithm, Variational Bayes, Decision Tree-Based methods, Support Vector Machines, MultiLayer Perceptron and \nother backpropagation neural network algorithms \n\n\n\n\n\n\nLiterature\n\n\nComputational Physics by Mark Newman \n\n\nNumerical Recipes, by Press. W. etal.  http://numerical.recipes\n\n\nAn Introduction to Statistical Learning, by James G. etal, \nhttp://www-bcf.usc.edu/~gareth/ISL/ISLR%20Sixth%20Printing.pdf\n\n\nA Survey of Computational Physics by Landau, R., Paez, M-J., Bordeianu, C.\nfree downlaod at http://www.compadre.org/psrc/items/detail.cfm?ID=11578\n\n\nOther resources will be provided according to the needs (e.g.  https://arxiv.org/pdf/1505.02965.pdf ...)\n\n\nSoftware\n\n\nyou are expected to use existing numerical analysis routines and not write your own. Many of these are already \nimplemented in python libraries (scipy, numpy...), or you can call Numerical Recipes C++ routines (as well as other) \nfrom python. See http://numerical.recipes for details. Routines that go with Landau's book are at \nhttp://www.science.oregonstate.edu/~landaur/Books/CPbook/Codes/PythonCodes/\n\n\nPrerequsites\n\n\nbasic introduction to Python programming at the level of PHY77, or first 4 chapters of Newman's book \n\n\nHomeworks\n\n\nweekly, Jupyter notebook in Python submissions\n\n\nNo final exam, but a final project for graduate students",
            "title": "Home"
        },
        {
            "location": "/README/#computational-physics-numerical-methods-data-science-and-statistics",
            "text": "The purpose of the course is to get aquainted with modern computational methods \nused in physics, including numerical analysis methods, data science and statistics. \nWe will also explore numerical and statistical methods that have been inspired by physics \nand/or created by physicists. Historically many of the methods have been developed for physics \napplications, a trend that continues today with more modern examples like Metropolis \nalgorithm, simulated annealing and Hamiltonian Monte Carlo.    Each week there will be a set of lectures discussing theoretical and practical underpinnings of the specific topic, \ntogether with its most common applications in physics and astronomy, followed by a homework assignment applying the \nmethods to physics and astronomy based applications.",
            "title": "Computational Physics: numerical methods, data science and statistics"
        },
        {
            "location": "/README/#syllabus",
            "text": "Function Integration: trapezoidal, Simpson, Romberg, gaussian quadratures    Special functions and function evaluation: Gamma, Bessel, spherical harmonics, function derivatives    Solving Linear Algebra: Gauss elimination, LU and Cholesky decomposition, singular value decomposition, sparse algebra    Eigensystems and matrix diagonalization, principal component analysis    Nonlinear sets of equations: relaxation, bisection, Newton's method    Optimization (minimization/maximization): steepest gradient descent, stochastic gradient descent, conjugate gradient, Newton and quasi-Newton (BFGS)    Interpolation and extrapolation of data. Polynomial, rational and spline interpolation, gaussian process    Fourier transforms: FFT, convolutions, power spectrum and correlation function, optimal (Wiener) filtering, wavelets    Ordinary differential equations: Euler, Runge Kutta, Bulirsch-Stoer, stiff equation solvers, leap-frog, boundary value problems    Partial differential equations: boundary value and initial value problems    Statistics: Bayes theorem, priors and posteriors, maximum likelihood and maximum a posterior, linear and \nnonlinear model fitting of data. Error estimation: covariance and Fisher information matrix, jackknife, bootstrap    Random processes and statistics: random number generators, Monte Carlo integration, \nMetropolois algorithm, Markov Chain Monte Carlo, Gibbs sampling, importance sampling, Hamiltonian Monte \nCarlo, simulated annealing    Classification and Inference with Machine Learning and Bayesian Statistics: Gaussian mixtures with expectation \nmaximization algorithm, Variational Bayes, Decision Tree-Based methods, Support Vector Machines, MultiLayer Perceptron and \nother backpropagation neural network algorithms",
            "title": "Syllabus"
        },
        {
            "location": "/README/#literature",
            "text": "Computational Physics by Mark Newman   Numerical Recipes, by Press. W. etal.  http://numerical.recipes  An Introduction to Statistical Learning, by James G. etal, \nhttp://www-bcf.usc.edu/~gareth/ISL/ISLR%20Sixth%20Printing.pdf  A Survey of Computational Physics by Landau, R., Paez, M-J., Bordeianu, C.\nfree downlaod at http://www.compadre.org/psrc/items/detail.cfm?ID=11578  Other resources will be provided according to the needs (e.g.  https://arxiv.org/pdf/1505.02965.pdf ...)",
            "title": "Literature"
        },
        {
            "location": "/README/#software",
            "text": "you are expected to use existing numerical analysis routines and not write your own. Many of these are already \nimplemented in python libraries (scipy, numpy...), or you can call Numerical Recipes C++ routines (as well as other) \nfrom python. See http://numerical.recipes for details. Routines that go with Landau's book are at \nhttp://www.science.oregonstate.edu/~landaur/Books/CPbook/Codes/PythonCodes/",
            "title": "Software"
        },
        {
            "location": "/README/#prerequsites",
            "text": "basic introduction to Python programming at the level of PHY77, or first 4 chapters of Newman's book",
            "title": "Prerequsites"
        },
        {
            "location": "/README/#homeworks",
            "text": "weekly, Jupyter notebook in Python submissions  No final exam, but a final project for graduate students",
            "title": "Homeworks"
        }
    ]
}